# Seminararbeit SS 2023 Michel Bauer ğŸ“–	ğŸˆ
## Die Struktur dieses Github-Repository basiert auf Kapitel 3 meiner Seminararbeit. Es zeigt die jeweiligen Schritte auf, die unternommen wurden, um den Datensatz zu generieren, eine explorative Datenanalyse durchzufÃ¼hren, die Modelle zu testen, zu evaluieren und die Anwendbarkeit der Modelle aufzuzeigen.

### Da der finale Datensatz und das Modell TabNet zu groÃŸ sind wurden zwei Release getÃ¤tigt
- Der erste Release beinhaltet den finalen Datensatz
- Der zweite Release die drei trainierten Modelle XGBoost, Random Forest und TabNet

### Notebook: Datensatz ğŸ’¾
In diesem Notebook wird aufgezeigt, wie der Datensatz generiert wurde
- Zuerst wurde mit der ESPN-API ein play-by-play Datensatz generiert
- Mithilfe der ESPN- und der FiveThirtyEight-API die Elozahlen fÃ¼r die Teams generiert. Dabei wurden die Elozahlen genommen, die fÃ¼raktuelle Saison und Woche aktuell waren
- ZuzÃ¤stlich wurde mit Hilfe der ESPN-API die Zuschauerquote im Stadium extrahiert
- Anhand dieses Datnsatzes wurden weitere Features gebildet
    - Die verbleibende Zeit im Spiel
    - Der Punkteabstand zwischen den zwei Teams
    - Das aktuell fÃ¼hrende Team
    - Und ein Feature, das anzeigt wie viele Scoring-SpielzÃ¼ge das zurÃ¼ckliegende Team benÃ¶tigt, um den Punktestand auszugleichen

### Notebook: EDA (Expolrative Daten Analyse) ğŸ“Š
Hier werden verschiedene Grafiken generiert, die zum VerstÃ¤ndnis der Daten beitragen:
- Eine Korrelationsmatrix: Sie zeigt die Korrelationen der Features untereinander an
- Ein Balken-Diagramm um zu visualisieren der Verteilung der Klassen im Datensatz
- Ein Balken-Diagramm, das aufzeigt in welchem Yardintervall die meisten Punkte erzielt werden
- Die Anderen Grafiken, die sich im Notebook verwendet, werden nicht fÃ¼r diese Arbeit verwendet

 ### Notebook: Training ğŸ§ 
 In diesem Notebook wird dargelegt, wie die einzelnen Modelle trainiert wurden. Dbei wird aufgezeigt, wie die Trainings-, Valdierungs-, und TrainingsdatensÃ¤tze aufgeteilt wurden. AuÃŸerdem wird dargelegt, wie die einzelnen Preprocessingschritte umgesetzt wurden. Die Modelle wurden mit folgenden Methoden trainiert:
 - XGBoost: Early-Stopping-Methode
 - Random Forest: Da es keine Early-stopping Methode gab, wurde hierzu manuell die beste BaumgrÃ¶ÃŸe evaluiert und anschlieÃŸend mit dieser GrÃ¶ÃŸe das Modell trainiert
 - TabNet: Early-Stopping-Methode

### Notebook: Evaluation ğŸ“ˆ

